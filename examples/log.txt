Collecting env info...
PyTorch version: 1.12.0+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.4 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
Clang version: Could not collect
CMake version: version 3.19.1
Libc version: glibc-2.31

Python version: 3.8.10 (default, Mar 15 2022, 12:22:08)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-107-generic-x86_64-with-glibc2.29
Is CUDA available: True
CUDA runtime version: 10.2.300
GPU models and configuration: 
GPU 0: Tesla V100-DGXS-32GB
GPU 1: Tesla V100-DGXS-32GB
GPU 2: Tesla V100-DGXS-32GB
GPU 3: Tesla V100-DGXS-32GB

Nvidia driver version: 470.103.01
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] kfac-pytorch==0.4.1
[pip3] numpy==1.17.4
[pip3] pytorch-lightning==0.8.3
[pip3] torch==1.12.0
[pip3] torchinfo==1.5.2
[pip3] torchmetrics==0.9.2
[pip3] torchvision==0.13.0
[conda] No relevant packages

Global rank 0 initialized: local_rank = 0, world_size = 4
Global rank 1 initialized: local_rank = 1, world_size = 4
Global rank 2 initialized: local_rank = 2, world_size = 4
Global rank 3 initialized: local_rank = 3, world_size = 4
Files already downloaded and verified
Files already downloaded and verified
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ResNet                                   --                        --
├─Conv2d: 1-1                            [8, 16, 32, 32]           432
├─BatchNorm2d: 1-2                       [8, 16, 32, 32]           32
├─Sequential: 1-3                        [8, 16, 32, 32]           --
│    └─BasicBlock: 2-1                   [8, 16, 32, 32]           --
│    │    └─Conv2d: 3-1                  [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-2             [8, 16, 32, 32]           32
│    │    └─Conv2d: 3-3                  [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-4             [8, 16, 32, 32]           32
│    │    └─Sequential: 3-5              [8, 16, 32, 32]           --
│    └─BasicBlock: 2-2                   [8, 16, 32, 32]           --
│    │    └─Conv2d: 3-6                  [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-7             [8, 16, 32, 32]           32
│    │    └─Conv2d: 3-8                  [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-9             [8, 16, 32, 32]           32
│    │    └─Sequential: 3-10             [8, 16, 32, 32]           --
│    └─BasicBlock: 2-3                   [8, 16, 32, 32]           --
│    │    └─Conv2d: 3-11                 [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-12            [8, 16, 32, 32]           32
│    │    └─Conv2d: 3-13                 [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-14            [8, 16, 32, 32]           32
│    │    └─Sequential: 3-15             [8, 16, 32, 32]           --
│    └─BasicBlock: 2-4                   [8, 16, 32, 32]           --
│    │    └─Conv2d: 3-16                 [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-17            [8, 16, 32, 32]           32
│    │    └─Conv2d: 3-18                 [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-19            [8, 16, 32, 32]           32
│    │    └─Sequential: 3-20             [8, 16, 32, 32]           --
│    └─BasicBlock: 2-5                   [8, 16, 32, 32]           --
│    │    └─Conv2d: 3-21                 [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-22            [8, 16, 32, 32]           32
│    │    └─Conv2d: 3-23                 [8, 16, 32, 32]           2,304
│    │    └─BatchNorm2d: 3-24            [8, 16, 32, 32]           32
│    │    └─Sequential: 3-25             [8, 16, 32, 32]           --
├─Sequential: 1-4                        [8, 32, 16, 16]           --
│    └─BasicBlock: 2-6                   [8, 32, 16, 16]           --
│    │    └─Conv2d: 3-26                 [8, 32, 16, 16]           4,608
│    │    └─BatchNorm2d: 3-27            [8, 32, 16, 16]           64
│    │    └─Conv2d: 3-28                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-29            [8, 32, 16, 16]           64
│    │    └─LambdaLayer: 3-30            [8, 32, 16, 16]           --
│    └─BasicBlock: 2-7                   [8, 32, 16, 16]           --
│    │    └─Conv2d: 3-31                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-32            [8, 32, 16, 16]           64
│    │    └─Conv2d: 3-33                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-34            [8, 32, 16, 16]           64
│    │    └─Sequential: 3-35             [8, 32, 16, 16]           --
│    └─BasicBlock: 2-8                   [8, 32, 16, 16]           --
│    │    └─Conv2d: 3-36                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-37            [8, 32, 16, 16]           64
│    │    └─Conv2d: 3-38                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-39            [8, 32, 16, 16]           64
│    │    └─Sequential: 3-40             [8, 32, 16, 16]           --
│    └─BasicBlock: 2-9                   [8, 32, 16, 16]           --
│    │    └─Conv2d: 3-41                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-42            [8, 32, 16, 16]           64
│    │    └─Conv2d: 3-43                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-44            [8, 32, 16, 16]           64
│    │    └─Sequential: 3-45             [8, 32, 16, 16]           --
│    └─BasicBlock: 2-10                  [8, 32, 16, 16]           --
│    │    └─Conv2d: 3-46                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-47            [8, 32, 16, 16]           64
│    │    └─Conv2d: 3-48                 [8, 32, 16, 16]           9,216
│    │    └─BatchNorm2d: 3-49            [8, 32, 16, 16]           64
│    │    └─Sequential: 3-50             [8, 32, 16, 16]           --
├─Sequential: 1-5                        [8, 64, 8, 8]             --
│    └─BasicBlock: 2-11                  [8, 64, 8, 8]             --
│    │    └─Conv2d: 3-51                 [8, 64, 8, 8]             18,432
│    │    └─BatchNorm2d: 3-52            [8, 64, 8, 8]             128
│    │    └─Conv2d: 3-53                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-54            [8, 64, 8, 8]             128
│    │    └─LambdaLayer: 3-55            [8, 64, 8, 8]             --
│    └─BasicBlock: 2-12                  [8, 64, 8, 8]             --
│    │    └─Conv2d: 3-56                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-57            [8, 64, 8, 8]             128
│    │    └─Conv2d: 3-58                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-59            [8, 64, 8, 8]             128
│    │    └─Sequential: 3-60             [8, 64, 8, 8]             --
│    └─BasicBlock: 2-13                  [8, 64, 8, 8]             --
│    │    └─Conv2d: 3-61                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-62            [8, 64, 8, 8]             128
│    │    └─Conv2d: 3-63                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-64            [8, 64, 8, 8]             128
│    │    └─Sequential: 3-65             [8, 64, 8, 8]             --
│    └─BasicBlock: 2-14                  [8, 64, 8, 8]             --
│    │    └─Conv2d: 3-66                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-67            [8, 64, 8, 8]             128
│    │    └─Conv2d: 3-68                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-69            [8, 64, 8, 8]             128
│    │    └─Sequential: 3-70             [8, 64, 8, 8]             --
│    └─BasicBlock: 2-15                  [8, 64, 8, 8]             --
│    │    └─Conv2d: 3-71                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-72            [8, 64, 8, 8]             128
│    │    └─Conv2d: 3-73                 [8, 64, 8, 8]             36,864
│    │    └─BatchNorm2d: 3-74            [8, 64, 8, 8]             128
│    │    └─Sequential: 3-75             [8, 64, 8, 8]             --
├─Linear: 1-6                            [8, 10]                   650
==========================================================================================
Total params: 464,154
Trainable params: 464,154
Non-trainable params: 0
Total mult-adds (M): 550.92
==========================================================================================
Input size (MB): 0.10
Forward/backward pass size (MB): 38.80
Params size (MB): 1.86
Estimated Total Size (MB): 40.75
==========================================================================================
KFACPreconditioner(
  accumulation_steps=1,
  allreduce_bucket_cap_mb=25,
  allreduce_method=AllreduceMethod.ALLREDUCE_BUCKETED,
  assignment=KAISAAssignment,
  assignment_strategy=AssignmentStrategy.COMPUTE,
  colocate_factors=True,
  compute_eigenvalue_outer_product=True,
  compute_method=ComputeMethod.EIGEN,
  damping=0.003,
  distributed_strategy=DistributedStrategy.COMM_OPT,
  factor_decay=0.95,
  factor_dtype=None,
  factor_update_steps=1,
  grad_scaler=False,
  grad_worker_fraction=1.0,
  inv_dtype=torch.float32,
  inv_update_steps=10,
  kl_clip=0.001,
  layers=32,
  loglevel=10,
  lr=<function get_optimizer.<locals>.<lambda> at 0x7fcdf439d8b0>,
  skip_layers=[],
  steps=0,
  symmetry_aware=False,
  update_factors_in_hook=True,
)
